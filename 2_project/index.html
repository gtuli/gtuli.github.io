<!DOCTYPE html>
<html lang='en'>
<head><meta charset='UTF-8'><title>Project</title></head>
<body>
<h1>2 Project</h1>
<img src='placeholder.jpg' alt='Project Graphic' style='width:300px;height:auto;'>
<h2>Key Questions Addressed</h2>
<ul>
<li>Can Multiple Biomarkers Beat One? Will combining several indicators (IgE, SPT, patient history, etc.) via an ML model yield better diagnostic accuracy for food allergy than any single test alone? The team hypothesized that a composite panel could capture the complex profile of allergy risk more effectively.</li>
<li>Who is Truly At-Risk? Using this ML-driven panel, can we predict which patients are at high risk of allergic reaction (and thus need precautions) versus those likely tolerant? In other words, determine who can safely undergo an oral food challenge and who might react, to inform clinical decision-making.</li>
<li>Adaptability and Scope: If successful for peanut, milk, and egg allergies (initial focus), can this diagnostic framework be retrained and extended to other foods and use-cases? For example, use the model as:</li>
<li>A therapy efficacy biomarker (is a patient’s risk decreasing after treatment?),</li>
<li>A predictive marker for outcomes of immunotherapies,</li>
<li>A prognostic marker for natural history (will a child outgrow an allergy?).</li>
</ul>
<h2>The Problem</h2>
<ul>
<li>Diagnostic Uncertainty: Many allergic patients hover in an indeterminate zone – e.g. moderate IgE levels that are not clearly negative or positive. Clinicians face a diagnostic dilemma when test results are inconclusive. Overly cautious interpretation leads to false positives (patients told to avoid foods they might actually tolerate), whereas underestimation can lead to false negatives (risking anaphylaxis in unsuspecting patients).</li>
<li>One-Size-Fits-None: No single biomarker captures the full complexity of food allergy, which involves immune, genetic, and environmental factors. For instance, IgE levels might be high due to sensitization without clinical allergy, and SPT size can vary by patient factors. The heterogeneity in allergy profiles (differences in age, geography, co-morbid conditions) means a more nuanced tool is needed.</li>
<li>Resource Constraints: Due to limited predictive power of current tests, many patients either undergo unnecessary food avoidance (with nutritional and quality-of-life impacts) or face delays in potentially safe food challenges. Improving diagnostic precision would better allocate who truly needs an OFC and spare others the burden of strict diets or risky tests.</li>
</ul>
<h2>The Importance</h2>
<ul>
<li>Patient Safety: By more accurately identifying high-risk individuals (who would react if challenged), the ML composite model helps prevent dangerous in-office anaphylactic reactions. Conversely, by spotting low-risk patients, it can save them from years of unnecessary food avoidance and enable earlier, safer introduction of foods.</li>
<li>Optimizing Healthcare Resources: OFCs require oversight by allergy specialists and sometimes emergency preparedness – a costly and time-consuming process. A reliable prediction tool would allow these challenges to be reserved for those who truly need them, improving clinic efficiency and reducing healthcare costs.</li>
<li>Enabling New Therapies: As therapies for food allergy (like oral immunotherapy) become more common, having a panel that can monitor response or predict outcomes is invaluable. It could indicate if a patient’s risk profile is improving with treatment or if they remain highly reactive, guiding therapy adjustments.</li>
<li>Generalizable Framework: The approach of using ML to validate composite biomarkers can serve as a template for other conditions (autoimmune diseases, etc.). It demonstrates how merging clinical data with modern ML can tackle diagnostic gaps, thereby influencing precision medicine approaches beyond allergies.</li>
</ul>
<h2>The Solution</h2>
<ul>
<li>Composite Biomarker Panel with ML: The team proposed and built a Machine Learning–assisted diagnostic algorithm that takes a panel of inputs – proven biomarkers (like specific IgE levels to peanut, milk, egg, IgE/total IgE ratios, SPT results) plus patient factors (age, symptoms, prior reaction history) – and outputs a risk assessment for food allergy. By training on patients with known challenge outcomes, the model “learns” the pattern of features that predict a true allergy.</li>
<li>Training and Validation: Using retrospective data from Boston Children’s Hospital’s food allergy clinics (including an existing SCAMP cohort), they compiled a dataset of patients who underwent OFCs with corresponding IgE, SPT, and clinical information. The data was split to train the ML model and then test it on a validation set. Regularization and feature selection techniques were employed to avoid overfitting given the diverse feature set.</li>
<li>ML Algorithm Exploration: Multiple algorithm classes were explored (e.g., logistic regression, random forest, gradient boosting, SVM) to find an optimal predictor. The preliminary chosen model was a classifier (initially a random forest) that output a probability of allergy. This model combined the information from all features – essentially learning the complex nonlinear interactions between, say, a combination of moderate IgE and large SPT that together signify high risk. The model continuously improves as new data (more challenge outcomes) are fed into training (an adaptive learning approach).</li>
<li>System Prototype – “ML-Allergy”: The project outlined a system architecture (nicknamed “ML-Allergy”) to implement this in practice. The architecture included:</li>
<li>An EHR Data Warehouse interface to pull relevant lab results and history for a patient,</li>
<li>Data preprocessing steps (ETL) to format and input these features into the model,</li>
<li>The ML model itself, and</li>
<li>An output module that would present a risk score and suggested interpretation to the clinician (e.g., “High risk – 85% chance of reaction; proceed with caution or alternative testing”).</li>
<li>Iterative Refinement: The model allows continuous learning. It can be retrained with new data or re-calibrated for different settings (e.g., if applied to another clinic with slightly different population, it can retrain on their outcomes). Future composite biomarkers (like emerging lab tests or genetic markers) can be integrated into the panel, making it a living diagnostic tool rather than a static formula.</li>
</ul>
<h2>Architecture Overview</h2>
<ul>
<li>Six-Key Component Pipeline: The proposed ML-Allergy system was broken into six key components within an overall ML pipeline:</li>
<li>Data Extraction & Integration: Relevant data (biochemical test results, clinical history) are pulled from the hospital’s EHR data warehouse. This included IgE values (including component-resolved diagnostics if available), SPT results, blood counts (eosinophils), demographics, etc.. The system was designed to easily incorporate these from existing databases via ETL processes.</li>
<li>Feature Engineering & Selection: A feature set of ~20–30 candidate predictors was defined (Table 1 in the project documentation lists these). Not all features may be available for every patient, so the pipeline can handle missing data and still output a prediction (with a confidence metric). Regularization methods in the ML training help rank feature importance and eliminate those that don’t improve accuracy.</li>
<li>Classifier Training Cycle: The core ML model goes through iterative training. The process was divided into four overlapping phases: data preprocessing, training, validation, and evaluation – depicted as hexagon steps (a–f) in an internal diagram. Various algorithms (from simple regression to complex ensembles) were tested under cross-validation to find the best-performing model without overfitting.</li>
<li>Model Evaluation & Tuning: Performance was measured primarily by AUC (Area Under ROC Curve), since this is a binary classification (allergic vs tolerant). The preliminary model already achieved an AUC of ~0.96 in internal testing, demonstrating superior performance over single biomarkers. The pipeline includes the ability to perform further tuning (adjusting thresholds to maximize negative predictive value, given safety concerns) and to compare algorithms.</li>
<li>Prediction Output & Decision Support: The final model output is a risk probability that can be translated into a user-friendly recommendation (e.g., “Low Risk – OFC can be considered under standard protocols” vs “High Risk – patient not a candidate for OFC; consider alternative diagnostics”). The project proposed integrating this into a clinician dashboard or report. The output would also show contributing factors (for transparency), such as “key predictors: high egg IgE and large SPT size” to help clinician interpret.</li>
<li>Retraining & Extension: The system was built to be extensible. As outcomes from more challenges are accumulated or as new types of biomarkers become available (e.g., basophil activation tests, epitope assays), those can be added to the model. The plan also included extending the approach to other foods once validated for the initial three; essentially a blueprint for each food allergen’s diagnostic model.</li>
<li>Data Flow Example: For a given patient, the system would automatically gather their allergy test results and history, input them into the ML model, and output a risk score. For instance: Patient X: peanut IgE 5 kU/L, peanut SPT 8 mm, history of eczema, age 2. The model might output “90% risk of reaction.” This result could prompt the clinician to avoid an OFC and perhaps proceed directly to a supervised food introduction in hospital or consider desensitization therapy.</li>
<li>Integration with Workflow: The architecture considered integration with existing hospital IT. Because it leverages the EHR warehouse, it could run in the background and flag patient records where an upcoming clinic visit involves food allergy – supplying the clinician with a “ML risk score” alongside lab results. This way, it acts as a true decision support system, seamlessly fitting into clinical workflow.</li>
</ul>
<h2>Results and Impacts</h2>
<ul>
<li>Improved Diagnostic Accuracy: The ML composite model outperformed individual tests. In preliminary validation, it achieved an AUC ~0.96 for predicting challenge outcomes, whereas IgE or SPT alone had significantly lower AUCs. This indicates a strong ability to correctly classify allergic vs non-allergic patients. In practical terms, it means fewer false positives (avoiding unnecessary diets) and fewer false negatives (avoiding dangerous challenge surprises).</li>
<li>Combination Matters: One key finding was that using combined measures yields a clearer separation between allergic and tolerant patients than any measure alone. For example, a graph of the model’s performance (Figure 1) showed the ML classifier’s ROC curve dominating those of IgE or SPT alone. This validated the hypothesis that multiple weak signals, when weighted properly by ML, produce a strong predictive signal.</li>
<li>Clinical Workflow Integration: By demonstrating that such a model can be derived, the project laid groundwork for integrating it into allergy practice. Physicians at BCH began exploring how to incorporate the risk score into patient discussions – e.g., using it to decide if an OFC should be deferred. The model’s output (with confidence levels) can be used to support insurance justifications for conducting or skipping an OFC, a practical impact on care decisions.</li>
<li>Patient Safety and Quality of Life: In practice, this tool improves patient safety – high-risk children can be routed to alternative management without undergoing a risky challenge. At the same time, low-risk children might be allowed to do food reintroductions sooner, potentially liberating them from strict dietary avoidance. This has a positive psychosocial impact, as families avoid needless anxiety and dietary burden.</li>
<li>Deployment and Use: As part of Dr. Tuli’s role, elements of this project were deployed in a pilot at Boston Children’s Hospital. Specifically, patient stratification models were implemented to assist in triage, meaning the allergy clinic started using the model’s risk assessment to prioritize which patients should get an OFC or need closer monitoring. Early anecdotal outcomes indicated more efficient use of challenge appointments and no serious reactions in cases where the model advised against challenge (suggesting it indeed caught high-risk cases).</li>
<li>Path for Future Research: The project’s results were promising enough that discussions for a multi-center study were initiated, to validate the model on broader populations. Additionally, it opened up research into which components of the panel were most predictive – for example, the model highlighted that the ratio of specific IgE to total IgE and certain patient history elements added significant predictive value, knowledge that can spur new research into allergy biomarkers.</li>
</ul>
<h2>Skills and Tools Used</h2>
<ul>
<li>Data Collection & Curation: Worked with hospital electronic health records (Epic) and research databases to extract relevant patient data. This involved SQL queries and Pandas data processing to merge lab results with clinical notes (for reaction history) in a de-identified manner.</li>
<li>Machine Learning (Python/Sklearn): Utilized Python’s scikit-learn and/or LightGBM for model development. Implemented cross-validation, grid search for hyperparameters, and regularization techniques (L1/L2) to handle feature selection in the presence of many correlated biomarkers.</li>
<li>Statistical Analysis: Employed statistical tests and metrics to evaluate model performance – ROC/AUC analysis, confidence intervals via bootstrapping, etc. Ensured the model’s negative predictive value was maximized (since missing a true allergy could be life-threatening). This required custom threshold tuning beyond generic accuracy optimization.</li>
<li>Domain Knowledge Integration: Mapped medical knowledge into the ML process, e.g., ensuring features like “history of anaphylaxis” were weighted appropriately. This required close collaboration with allergists to encode clinical logic (like considering an IgE level “high” or “moderate” in context) and to interpret model outputs reasonably.</li>
<li>EHR Data Handling: Experience with healthcare data standards and privacy: working with HIPAA-compliant datasets and understanding clinical terminologies (ICD-10 codes for allergies, LOINC codes for lab tests, etc.). The project leveraged FHIR resources from the EHR to identify relevant data fields, building a bridge between the ML system and clinical data sources.</li>
<li>Presentation & Communication: Communicated results to clinical stakeholders in easy-to-understand terms (e.g., “The model would allow us to avoid X% of unnecessary challenges while missing virtually no true allergies”). Created visual aids like calibration plots and decision curves for hospital meetings. This mix of technical and clinical communication was key to gaining physician buy-in.</li>
</ul>
<h2>Cross-project Capabilities</h2>
<ul>
<li>Clinical Decision Support (CDS): This project is a prime example of a CDS tool – skills in building such tools (data ingestion, model integration into workflow, clinician feedback loop) are transferrable to other hospital projects. Dr. Tuli applied this know-how in subsequent initiatives, like developing ICU decision support (Project 4) and maternal-infant care support (Projects 5–6).</li>
<li>End-to-End Pipeline Ownership: The ability to see a project through from data extraction to model deployment and evaluation, as demonstrated here, is a common thread in Dr. Tuli’s projects. In his role, he often “owned” the entire model lifecycle – this holistic skill means he can ensure all parts (data, model, UI, stakeholder training) work in concert.</li>
<li>Interdisciplinary Collaboration: Working at the intersection of data science and clinical expertise (allergists in this case) built collaboration skills that Dr. Tuli carried to other domains. For instance, he similarly collaborated with ophthalmologists for the Vision project and with intensivists for the ICU project, showing an aptitude for quickly learning new domain jargon and needs.</li>
<li>Regulatory and Ethical Awareness: Handling patient data and making predictions in healthcare demands an understanding of compliance and ethical responsibility. Through this project, Dr. Tuli gained experience in navigating IRB approvals, patient consent (for using retrospective data), and explaining algorithms’ limitations to avoid over-reliance. This is crucial across all healthcare ML projects, including those dealing with sensitive populations (like mother-infant dyads).</li>
<li>Generalizable Modeling Approach: The approach of combining domain features in an ML model can be adapted widely. Dr. Tuli has demonstrated the template: define problem-specific features, collect outcomes, apply ML, evaluate rigorously, and integrate in practice. This template has been his blueprint across projects – whether predicting vision outcomes or ICU oxygen levels – showcasing a replicable methodology.</li>
</ul>
<h2>Published Papers/Tools</h2>
<ul>
<li>Internal Research Proposal: “Utilizing Machine Learning to Validate a Composite Biomarker Panel for Diagnostic Evaluation of Food Allergies” – an internal white paper outlining the project’s rationale and design. (Not publicly published, but circulated within the hospital and to project sponsors.)</li>
<li>Institutional Adoption: The methodologies from this project contributed to improved clinical protocols at Boston Children’s. While not a traditional publication, the work was presented at hospital grand rounds and at an internal innovation showcase in 2020, spreading awareness of ML applications in allergy diagnostics.</li>
<li>Related Publication: Although this specific project’s results are proprietary to the hospital, Dr. Tuli’s contribution to a related area is reflected in a publication on patient stratification using digital data (Boston Children’s work on ranking US hospitals via patient experience on Twitter). It exemplifies the fusion of data and healthcare decisions, a theme central to this project as well.</li>
<li>Tool Status: A prototype “Allergy ML Risk Calculator” tool (Excel-based and Python API) was developed, allowing clinicians to input patient metrics and receive a risk estimate. This tool is in pilot evaluation and targeted for potential inclusion in the electronic health record decision support modules.</li>
</ul>
<p><a href='../index.html'>&larr; Back to Projects</a></p>
</body></html>